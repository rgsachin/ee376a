{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Activation, Bidirectional, Add, Concatenate, Embedding, Lambda, concatenate, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM, Multiply, Lambda,TimeDistributed,GRU\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Masking\n",
    "from keras import backend as K\n",
    "from keras import losses\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "import copy\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 10\n",
    "hidden_size = 20\n",
    "sequential_code_channel_size=3\n",
    "logical_variables = [1,2]\n",
    "logical_operator = {\n",
    "    3:'or',\n",
    "    4:'and'\n",
    "}\n",
    "none_var = 0\n",
    "num_vocab=5\n",
    "batch_size=50\n",
    "episode_len = 10\n",
    "num_epoch = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoder_agent():\n",
    "    x_i = Input(shape=(None,1))\n",
    "    x_o = Input(shape=(None,1))\n",
    "\n",
    "    y = TimeDistributed(Embedding(num_vocab, embed_size))(x_i)\n",
    "    y = Lambda(lambda z:K.squeeze(z,axis=-2))(y)\n",
    "    print(K.int_shape(y))\n",
    "    y,h,c = LSTM(hidden_size,return_state=True)(y)\n",
    "    \n",
    "    y,_,_ = LSTM(hidden_size,return_sequences=True, return_state=True)(x_o,initial_state=[h,c])\n",
    "    \n",
    "    y = TimeDistributed(Dense(sequential_code_channel_size,activation='softmax'))(y)    \n",
    "    \n",
    "    model = Model(inputs=[x_i,x_o],outputs=y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decoder_agent():\n",
    "    x_i = Input(shape=(None,1))\n",
    "    x_o = Input(shape=(None,1))\n",
    "\n",
    "    y = TimeDistributed(Embedding(sequential_code_channel_size, embed_size))(x_i)\n",
    "    y = Lambda(lambda z:K.squeeze(z,axis=-2))(y)\n",
    "    print(K.int_shape(y))\n",
    "    y,h,c = LSTM(hidden_size,return_state=True)(y)\n",
    "    \n",
    "    y,_,_ = LSTM(hidden_size,return_sequences=True, return_state=True)(x_o,initial_state=[h,c])\n",
    "    \n",
    "    y = TimeDistributed(Dense(num_vocab,activation='softmax'))(y)    \n",
    "    \n",
    "    model = Model(inputs=[x_i,x_o],outputs=y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(expression1,expression2):\n",
    "    for op in logical_operator.keys():\n",
    "        expression1 = expression1.replace(str(op),logical_operator[op])\n",
    "        expression2 = expression2.replace(str(op),logical_operator[op])\n",
    "    for v1 in [True,False]:\n",
    "        for v2 in [True,False]:\n",
    "            sol1=eval(expression1.replace('1',str(v1)).replace('2',str(v2)).strip())\n",
    "            sol2=eval(expression2.replace('1',str(v1)).replace('2',str(v2)).strip())\n",
    "            if sol1!=sol2:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_function('1 3 2','2 3 1'),score_function('1 3 2','2 4 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 10)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, None, 1, 10)  40          input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, None, 10)     0           time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                  [(None, 20), (None,  2480        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  [(None, None, 20), ( 1760        input_27[0][0]                   \n",
      "                                                                 lstm_24[0][1]                    \n",
      "                                                                 lstm_24[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, None, 3)      63          lstm_25[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,343\n",
      "Trainable params: 4,343\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_agent = get_encoder_agent()\n",
    "encoder_agent.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 10)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, None, 1, 10)  30          input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, None, 10)     0           time_distributed_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  [(None, 20), (None,  2480        lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  [(None, None, 20), ( 1760        input_29[0][0]                   \n",
      "                                                                 lstm_26[0][1]                    \n",
      "                                                                 lstm_26[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, None, 4)      84          lstm_27[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,354\n",
      "Trainable params: 4,354\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_agent = get_decoder_agent()\n",
    "decoder_agent.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_agent.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "encoder_agent.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_expression():\n",
    "    return [random.choice([1,2]),random.choice([3,4]),random.choice([1,2])]\n",
    "def simulator_generator_example():\n",
    "    batch = []\n",
    "    while True:\n",
    "        batch.append(generate_expression())\n",
    "        if len(batch) % batch_size ==0 and len(batch)!=0:\n",
    "            batch = np.expand_dims(batch,axis=-1)\n",
    "            yield [batch,np.zeros(batch.shape)]\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_expression(exp_arr):\n",
    "    return ' '.join([str(z) for z in exp_arr]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sim_gen = simulator_generator_example()\n",
    "\n",
    "for epoch_num in range(num_epoch):\n",
    "    batch = sim_gen.__next__()\n",
    "    encoder_output = encoder_agent.predict(batch)\n",
    "    batch = sim_gen.__next__()\n",
    "    encoder_output = encoder_agent.predict(batch)\n",
    "    encoder_output_disctretised = np.argmax(encoder_output,axis=-1)\n",
    "    encoder_output_disctretised=np.expand_dims(encoder_output_disctretised,axis=-1)\n",
    "    dummy = np.zeros((encoder_output_disctretised.shape))\n",
    "    decoder_output=decoder_agent.predict([encoder_output_disctretised,dummy])\n",
    "\n",
    "    decoder_output=decoder_agent.predict([encoder_output_disctretised,dummy])\n",
    "    decoder_output_discrete = np.argmax(decoder_output,axis=-1)\n",
    "    rewards = []\n",
    "    for idx,(ip,op) in enumerate(zip(batch,decoder_output_discrete)):\n",
    "        try:\n",
    "            exp_1=make_expression(ip)\n",
    "            exp_2=make_expression(op)\n",
    "            reward = score_function(exp_1,exp_2)\n",
    "            if reward:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = -1\n",
    "        except:\n",
    "            reward = -1\n",
    "        rewards.append(reward)\n",
    "    encoder_agent.fit(batch,reward,epochs=1,batch_size=lwn(batch),callbacks=[tb_callback])\n",
    "    encoder_agent.fit([encoder_output_disctretised,dummy],reward,epochs=1,batch_size=lwn(batch),callbacks=[tb_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
